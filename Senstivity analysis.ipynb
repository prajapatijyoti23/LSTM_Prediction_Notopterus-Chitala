{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis by using different time steps in best models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diamond Harbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import ConvLSTM2D\n",
    "rmse = []\n",
    "cfu= []\n",
    "cfl= []\n",
    "nsteps = []\n",
    "for j in [4,6,8,10]:\n",
    "    for w in range(20):\n",
    "        nsteps.append(j)\n",
    "        # Defining a function to split a univariate sequence into samples for LSTM Model\n",
    "        def split_sequence(sequence, n_steps):\n",
    "            X, y = list(), list()\n",
    "            for i in range(len(sequence)):\n",
    "                # find the end of this pattern\n",
    "                end_ix = i + n_steps\n",
    "                # check if we are beyond the sequence\n",
    "                if end_ix > len(sequence)-1:\n",
    "                    break\n",
    "                # gather input and output parts of the pattern\n",
    "                seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "                X.append(seq_x)\n",
    "                y.append(seq_y)\n",
    "            return array(X), array(y)\n",
    "\n",
    "        # define input sequence\n",
    "        data=pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "        tdw=pd.Series([2016])\n",
    "        train_data=data[~data['Year '].isin(tdw)]\n",
    "        test_data=data[data['Year '].isin(tdw)]\n",
    "        test_data=test_data.set_index(np.arange(0,len(test_data)))\n",
    "        n_step1 = j\n",
    "        # split into samples\n",
    "        X, y = split_sequence(train_data.Value, n_step1)\n",
    "        # reshape from [samples, timesteps] into [samples, timesteps, rows, columns, features]\n",
    "        n_features = 1\n",
    "        n_seq = 2\n",
    "        n_step2 = int(n_step1/2)\n",
    "        X = X.reshape((X.shape[0], n_seq, 1, n_step2, n_features))\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu', input_shape=(n_seq, 1, n_step2, n_features)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        # fit model\n",
    "        model.fit(X, y, epochs=500, verbose=0)\n",
    "        # demonstrate prediction\n",
    "\n",
    "        x_input, y_input = split_sequence(test_data.Value, n_step1)\n",
    "\n",
    "        x_input = x_input.reshape((x_input.shape[0], n_seq,1, n_step2, n_features))\n",
    "\n",
    "        #Prediction on Test dataset\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        yhat=yhat.reshape(-1)\n",
    "\n",
    "        # Calculating Mean Sum of squared error\n",
    "        mse=1/len(yhat)*sum(np.square(y_input-yhat))\n",
    "        mse\n",
    "\n",
    "        #95% Confidence Interval at alpha=0.05, zalpha/2=1.96\n",
    "        yhat_b = 1/len(yhat)*sum(yhat)\n",
    "        ieta = np.sqrt(1/len(yhat)*sum(np.square(yhat-yhat_b)))\n",
    "        CI_L = yhat_b-1.96*ieta\n",
    "        CI_U = yhat_b+1.96*ieta\n",
    "\n",
    "        # Confidence Prediction at each step points\n",
    "        import matplotlib.pyplot as plt\n",
    "        y_l=yhat-1.96*ieta\n",
    "        y_u=yhat+1.96*ieta\n",
    "\n",
    "       \n",
    "        print('RMSE',np.sqrt(mse))\n",
    "        rmse.append(np.sqrt(mse))\n",
    "        print('Confidence Interval :', CI_L , CI_U)\n",
    "        cfu.append(CI_U)\n",
    "        cfl.append(CI_L)\n",
    "        \n",
    "result=pd.DataFrame({'RMSE':rmse,'CI_U':cfu,'CI_L':cfl,'nsteps':nsteps})\n",
    "result.to_csv('Convlstm_DH_sensitivity'+'n_step_.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Malancha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import ConvLSTM2D\n",
    "rmse = []\n",
    "cfu= []\n",
    "cfl= []\n",
    "nsteps = []\n",
    "for j in [4,6,8,10]:\n",
    "    for w in range(20):\n",
    "        nsteps.append(j)\n",
    "        # Defining a function to split a univariate sequence into samples for LSTM Model\n",
    "        def split_sequence(sequence, n_steps):\n",
    "            X, y = list(), list()\n",
    "            for i in range(len(sequence)):\n",
    "                # find the end of this pattern\n",
    "                end_ix = i + n_steps\n",
    "                # check if we are beyond the sequence\n",
    "                if end_ix > len(sequence)-1:\n",
    "                    break\n",
    "                # gather input and output parts of the pattern\n",
    "                seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "                X.append(seq_x)\n",
    "                y.append(seq_y)\n",
    "            return array(X), array(y)\n",
    "\n",
    "        # define input sequence\n",
    "        data=pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet2')\n",
    "\n",
    "        tdw=pd.Series([2016])\n",
    "        train_data=data[~data['Year '].isin(tdw)]\n",
    "        test_data=data[data['Year '].isin(tdw)]\n",
    "        test_data=test_data.set_index(np.arange(0,len(test_data)))\n",
    "        n_step1 = j\n",
    "        # split into samples\n",
    "        X, y = split_sequence(train_data.Value, n_step1)\n",
    "        # reshape from [samples, timesteps] into [samples, timesteps, rows, columns, features]\n",
    "        n_features = 1\n",
    "        n_seq = 2\n",
    "        n_step2 = int(n_step1/2)\n",
    "        X = X.reshape((X.shape[0], n_seq, 1, n_step2, n_features))\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu', input_shape=(n_seq, 1, n_step2, n_features)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        # fit model\n",
    "        model.fit(X, y, epochs=500, verbose=0)\n",
    "        # demonstrate prediction\n",
    "\n",
    "        x_input, y_input = split_sequence(test_data.Value, n_step1)\n",
    "        x_input = x_input.reshape((x_input.shape[0], n_seq,1, n_step2, n_features))\n",
    "\n",
    "        #Prediction on Test dataset\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        yhat=yhat.reshape(-1)\n",
    "\n",
    "        # Calculating Mean Sum of squared error\n",
    "        mse=1/len(yhat)*sum(np.square(y_input-yhat))\n",
    "        mse\n",
    "\n",
    "        #95% Confidence Interval at alpha=0.05, zalpha/2=1.96\n",
    "        yhat_b = 1/len(yhat)*sum(yhat)\n",
    "        ieta = np.sqrt(1/len(yhat)*sum(np.square(yhat-yhat_b)))\n",
    "        CI_L = yhat_b-1.96*ieta\n",
    "        CI_U = yhat_b+1.96*ieta\n",
    "\n",
    "        # Confidence Prediction at each step points\n",
    "        import matplotlib.pyplot as plt\n",
    "        y_l=yhat-1.96*ieta\n",
    "        y_u=yhat+1.96*ieta\n",
    "\n",
    "       \n",
    "        print('RMSE',np.sqrt(mse))\n",
    "        rmse.append(np.sqrt(mse))\n",
    "        print('Confidence Interval :', CI_L , CI_U)\n",
    "        cfu.append(CI_U)\n",
    "        cfl.append(CI_L)\n",
    "        \n",
    "result=pd.DataFrame({'RMSE':rmse,'CI_U':cfu,'CI_L':cfl,'nsteps':nsteps})\n",
    "result.to_csv('Convlstm_M_sensitivity'+'n_step_.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raidighi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Raidighifrom numpy import array\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import ConvLSTM2D\n",
    "rmse = []\n",
    "cfu= []\n",
    "cfl= []\n",
    "nsteps = []\n",
    "for j in [4,6,8,10]:\n",
    "    for w in range(20):\n",
    "        nsteps.append(j)\n",
    "        # Defining a function to split a univariate sequence into samples for LSTM Model\n",
    "        def split_sequence(sequence, n_steps):\n",
    "            X, y = list(), list()\n",
    "            for i in range(len(sequence)):\n",
    "                # find the end of this pattern\n",
    "                end_ix = i + n_steps\n",
    "                # check if we are beyond the sequence\n",
    "                if end_ix > len(sequence)-1:\n",
    "                    break\n",
    "                # gather input and output parts of the pattern\n",
    "                seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "                X.append(seq_x)\n",
    "                y.append(seq_y)\n",
    "            return array(X), array(y)\n",
    "\n",
    "        # define input sequence\n",
    "        data=pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet3')\n",
    "\n",
    "        tdw=pd.Series([2016])\n",
    "        train_data=data[~data['Year '].isin(tdw)]\n",
    "        test_data=data[data['Year '].isin(tdw)]\n",
    "        test_data=test_data.set_index(np.arange(0,len(test_data)))\n",
    "        n_step1 = j\n",
    "        # split into samples\n",
    "        X, y = split_sequence(train_data.Value, n_step1)\n",
    "        # reshape from [samples, timesteps] into [samples, timesteps, rows, columns, features]\n",
    "        n_features = 1\n",
    "        n_seq = 2\n",
    "        n_step2 = int(n_step1/2)\n",
    "        X = X.reshape((X.shape[0], n_seq, 1, n_step2, n_features))\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu', input_shape=(n_seq, 1, n_step2, n_features)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        # fit model\n",
    "        model.fit(X, y, epochs=500, verbose=0)\n",
    "        # demonstrate prediction\n",
    "\n",
    "        x_input, y_input = split_sequence(test_data.Value, n_step1)\n",
    "\n",
    "        x_input = x_input.reshape((x_input.shape[0], n_seq,1, n_step2, n_features))\n",
    "\n",
    "        #Prediction on Test dataset\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "\n",
    "        yhat=yhat.reshape(-1)\n",
    "\n",
    "        # Calculating Mean Sum of squared error\n",
    "        mse=1/len(yhat)*sum(np.square(y_input-yhat))\n",
    "        mse\n",
    "\n",
    "        #95% Confidence Interval at alpha=0.05, zalpha/2=1.96\n",
    "        yhat_b = 1/len(yhat)*sum(yhat)\n",
    "        ieta = np.sqrt(1/len(yhat)*sum(np.square(yhat-yhat_b)))\n",
    "        CI_L = yhat_b-1.96*ieta\n",
    "        CI_U = yhat_b+1.96*ieta\n",
    "\n",
    "        # Confidence Prediction at each step points\n",
    "        import matplotlib.pyplot as plt\n",
    "        y_l=yhat-1.96*ieta\n",
    "        y_u=yhat+1.96*ieta\n",
    "\n",
    "       \n",
    "        print('RMSE',np.sqrt(mse))\n",
    "        rmse.append(np.sqrt(mse))\n",
    "        print('Confidence Interval :', CI_L , CI_U)\n",
    "        cfu.append(CI_U)\n",
    "        cfl.append(CI_L)\n",
    "        \n",
    "result=pd.DataFrame({'RMSE':rmse,'CI_U':cfu,'CI_L':cfl,'nsteps':nsteps})\n",
    "result.to_csv('Convlstm_R_sensitivity'+'n_step_.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diamond Harbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate lstm example\n",
    "### Diamond Harbourfrom numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Embedding\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "rmse = []\n",
    "cfu= []\n",
    "cfl= []\n",
    "nsteps = []\n",
    "for j in [3,5,7,9]:\n",
    "    for i in range(20):\n",
    "        nsteps.append(j)\n",
    "        # Defining a function to split a univariate sequence into samples for LSTM Model\n",
    "        def split_sequence(sequence, n_steps):\n",
    "            X, y = list(), list()\n",
    "            for i in range(len(sequence)):\n",
    "                # find the end of this pattern\n",
    "                end_ix = i + n_steps\n",
    "                # check if we are beyond the sequence\n",
    "                if end_ix > len(sequence)-1:\n",
    "                    break\n",
    "                # gather input and output parts of the pattern\n",
    "                seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "                X.append(seq_x)\n",
    "                y.append(seq_y)\n",
    "            return array(X), array(y)\n",
    "\n",
    "        # define input sequence\n",
    "        data=pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "        tdw=pd.Series([2016])\n",
    "        train_data=data[~data['Year '].isin(tdw)]\n",
    "        test_data=data[data['Year '].isin(tdw)]\n",
    "        test_data=test_data.set_index(np.arange(0,len(test_data)))\n",
    "\n",
    "        # choose a number of time steps\n",
    "        n_steps = j\n",
    "        # split into samples\n",
    "        X, y = split_sequence(train_data.Value, n_steps)\n",
    "\n",
    "        # reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "        n_features = 1\n",
    "        X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "        model.add(Dense(1))\n",
    "       \n",
    "        # compile model\n",
    "        model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "        # fit model\n",
    "\n",
    "        history=model.fit(X, y, epochs=200, verbose=0)\n",
    "        \n",
    "        # split into samples\n",
    "        x_input, y_input = split_sequence(test_data.Value, n_steps)\n",
    "\n",
    "        x_input = x_input.reshape((x_input.shape[0], x_input.shape[1], n_features))\n",
    "\n",
    "        #Prediction on Test dataset\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "   \n",
    "        yhat=yhat.reshape(-1)\n",
    "\n",
    "        # Calculating Mean Sum of squared error\n",
    "        mse=1/len(yhat)*sum(np.square(y_input-yhat))\n",
    "        mse\n",
    "\n",
    "        #95% Confidence Interval at alpha=0.05, zalpha/2=1.96\n",
    "        yhat_b = 1/len(yhat)*sum(yhat)\n",
    "        ieta = np.sqrt(1/len(yhat)*sum(np.square(yhat-yhat_b)))\n",
    "        CI_L = yhat_b-1.96*ieta\n",
    "        CI_U = yhat_b+1.96*ieta\n",
    "\n",
    "        # Confidence Prediction at each step points\n",
    "        import matplotlib.pyplot as plt\n",
    "        y_l=yhat-1.96*ieta\n",
    "        y_u=yhat+1.96*ieta\n",
    "\n",
    "        \n",
    "        print('RMSE',np.sqrt(mse))\n",
    "        rmse.append(np.sqrt(mse))\n",
    "        print('Confidence Interval :', CI_L , CI_U)\n",
    "        cfu.append(CI_U)\n",
    "        cfl.append(CI_L)\n",
    "        \n",
    "result=pd.DataFrame({'RMSE':rmse,'CI_U':cfu,'CI_L':cfl,'nsteps':nsteps})\n",
    "result.to_csv('Vanillalstm_DH_sensitivity'+'n_step_.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Malancha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate lstm example\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "### Malanchafrom keras.layers import LSTM\n",
    "from keras.layers import Dense, Embedding\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "rmse = []\n",
    "cfu= []\n",
    "cfl= []\n",
    "nsteps = []\n",
    "for j in [3,5,7,9]:\n",
    "    for i in range(20):\n",
    "        nsteps.append(j)\n",
    "        # Defining a function to split a univariate sequence into samples for LSTM Model\n",
    "        def split_sequence(sequence, n_steps):\n",
    "            X, y = list(), list()\n",
    "            for i in range(len(sequence)):\n",
    "                # find the end of this pattern\n",
    "                end_ix = i + n_steps\n",
    "                # check if we are beyond the sequence\n",
    "                if end_ix > len(sequence)-1:\n",
    "                    break\n",
    "                # gather input and output parts of the pattern\n",
    "                seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "                X.append(seq_x)\n",
    "                y.append(seq_y)\n",
    "            return array(X), array(y)\n",
    "\n",
    "        # define input sequence\n",
    "        data=pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet2')\n",
    "\n",
    "        tdw=pd.Series([2016])\n",
    "        train_data=data[~data['Year '].isin(tdw)]\n",
    "        test_data=data[data['Year '].isin(tdw)]\n",
    "        test_data=test_data.set_index(np.arange(0,len(test_data)))\n",
    "\n",
    "        # choose a number of time steps\n",
    "        n_steps = j\n",
    "        # split into samples\n",
    "        X, y = split_sequence(train_data.Value, n_steps)\n",
    "\n",
    "        # reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "        n_features = 1\n",
    "        X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "        model.add(Dense(1))\n",
    "        #model.compile(optimizer='adam', loss='mse')\n",
    "        # compile model\n",
    "        model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "        # fit model\n",
    "\n",
    "        history=model.fit(X, y, epochs=200, verbose=0)\n",
    "        \n",
    "        # split into samples\n",
    "        x_input, y_input = split_sequence(test_data.Value, n_steps)\n",
    "\n",
    "        x_input = x_input.reshape((x_input.shape[0], x_input.shape[1], n_features))\n",
    "\n",
    "        #Prediction on Test dataset\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "      \n",
    "        yhat=yhat.reshape(-1)\n",
    "\n",
    "        # Calculating Mean Sum of squared error\n",
    "        mse=1/len(yhat)*sum(np.square(y_input-yhat))\n",
    "        mse\n",
    "\n",
    "        #95% Confidence Interval at alpha=0.05, zalpha/2=1.96\n",
    "        yhat_b = 1/len(yhat)*sum(yhat)\n",
    "        ieta = np.sqrt(1/len(yhat)*sum(np.square(yhat-yhat_b)))\n",
    "        CI_L = yhat_b-1.96*ieta\n",
    "        CI_U = yhat_b+1.96*ieta\n",
    "\n",
    "        # Confidence Prediction at each step points\n",
    "        import matplotlib.pyplot as plt\n",
    "        y_l=yhat-1.96*ieta\n",
    "        y_u=yhat+1.96*ieta\n",
    "\n",
    "        \n",
    "        print('RMSE',np.sqrt(mse))\n",
    "        rmse.append(np.sqrt(mse))\n",
    "        print('Confidence Interval :', CI_L , CI_U)\n",
    "        cfu.append(CI_U)\n",
    "        cfl.append(CI_L)\n",
    "        \n",
    "result=pd.DataFrame({'RMSE':rmse,'CI_U':cfu,'CI_L':cfl,'nsteps':nsteps})\n",
    "result.to_csv('Vanillalstm_M_sensitivity'+'n_step_.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raidighi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Raidighi# univariate lstm example\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Embedding\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "rmse = []\n",
    "cfu= []\n",
    "cfl= []\n",
    "nsteps = []\n",
    "for j in [3,5,7,9]:\n",
    "    for i in range(20):\n",
    "        nsteps.append(j)\n",
    "        # Defining a function to split a univariate sequence into samples for LSTM Model\n",
    "        def split_sequence(sequence, n_steps):\n",
    "            X, y = list(), list()\n",
    "            for i in range(len(sequence)):\n",
    "                # find the end of this pattern\n",
    "                end_ix = i + n_steps\n",
    "                # check if we are beyond the sequence\n",
    "                if end_ix > len(sequence)-1:\n",
    "                    break\n",
    "                # gather input and output parts of the pattern\n",
    "                seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "                X.append(seq_x)\n",
    "                y.append(seq_y)\n",
    "            return array(X), array(y)\n",
    "\n",
    "        # define input sequence\n",
    "        data=pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet3')\n",
    "\n",
    "        tdw=pd.Series([2016])\n",
    "        train_data=data[~data['Year '].isin(tdw)]\n",
    "        test_data=data[data['Year '].isin(tdw)]\n",
    "        test_data=test_data.set_index(np.arange(0,len(test_data)))\n",
    "\n",
    "        # choose a number of time steps\n",
    "        n_steps = j\n",
    "        # split into samples\n",
    "        X, y = split_sequence(train_data.Value, n_steps)\n",
    "\n",
    "        # reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "        n_features = 1\n",
    "        X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "        model.add(Dense(1))\n",
    "        \n",
    "        # compile model\n",
    "        model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "        # fit model\n",
    "\n",
    "        history=model.fit(X, y, epochs=200, verbose=0)\n",
    "        \n",
    "        # split into samples\n",
    "        x_input, y_input = split_sequence(test_data.Value, n_steps)\n",
    "\n",
    "        x_input = x_input.reshape((x_input.shape[0], x_input.shape[1], n_features))\n",
    "\n",
    "        #Prediction on Test dataset\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "\n",
    "        yhat=yhat.reshape(-1)\n",
    "\n",
    "        # Calculating Mean Sum of squared error\n",
    "        mse=1/len(yhat)*sum(np.square(y_input-yhat))\n",
    "        mse\n",
    "\n",
    "        #95% Confidence Interval at alpha=0.05, zalpha/2=1.96\n",
    "        yhat_b = 1/len(yhat)*sum(yhat)\n",
    "        ieta = np.sqrt(1/len(yhat)*sum(np.square(yhat-yhat_b)))\n",
    "        CI_L = yhat_b-1.96*ieta\n",
    "        CI_U = yhat_b+1.96*ieta\n",
    "\n",
    "        # Confidence Prediction at each step points\n",
    "        import matplotlib.pyplot as plt\n",
    "        y_l=yhat-1.96*ieta\n",
    "        y_u=yhat+1.96*ieta\n",
    "\n",
    "        \n",
    "        print('RMSE',np.sqrt(mse))\n",
    "        rmse.append(np.sqrt(mse))\n",
    "        print('Confidence Interval :', CI_L , CI_U)\n",
    "        cfu.append(CI_U)\n",
    "        cfl.append(CI_L)\n",
    "        \n",
    "result=pd.DataFrame({'RMSE':rmse,'CI_U':cfu,'CI_L':cfl,'nsteps':nsteps})\n",
    "result.to_csv('Vanillalstm_R_sensitivity'+'n_step_.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diamond Harbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Diamond Harbourfrom numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "rmse = []\n",
    "cfu= []\n",
    "cfl= []\n",
    "nsteps = []\n",
    "for j in [3,5,7,9]:\n",
    "    for i in range(20):\n",
    "        nsteps.append(j)\n",
    "        # Defining a function to split a univariate sequence into samples for LSTM Model\n",
    "        def split_sequence(sequence, n_steps):\n",
    "            X, y = list(), list()\n",
    "            for i in range(len(sequence)):\n",
    "                # find the end of this pattern\n",
    "                end_ix = i + n_steps\n",
    "                # check if we are beyond the sequence\n",
    "                if end_ix > len(sequence)-1:\n",
    "                    break\n",
    "                # gather input and output parts of the pattern\n",
    "                seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "                X.append(seq_x)\n",
    "                y.append(seq_y)\n",
    "            return array(X), array(y)\n",
    "\n",
    "        # define input sequence\n",
    "        data=pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "        tdw=pd.Series([2016])\n",
    "        train_data=data[~data['Year '].isin(tdw)]\n",
    "        test_data=data[data['Year '].isin(tdw)]\n",
    "        test_data=test_data.set_index(np.arange(0,len(test_data)))\n",
    "        n_steps = j\n",
    "        # split into samples\n",
    "        X, y = split_sequence(train_data.Value, n_steps)\n",
    "        # reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "        n_features = 1\n",
    "        X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "        model.add(LSTM(50, activation='relu'))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        # fit model\n",
    "        model.fit(X, y, epochs=200, verbose=0)\n",
    "        # demonstrate prediction\n",
    "        # split into samples\n",
    "        x_input, y_input = split_sequence(test_data.Value, n_steps)\n",
    "\n",
    "    \n",
    "        x_input = x_input.reshape((x_input.shape[0], x_input.shape[1], n_features))\n",
    "\n",
    "        #Prediction on Test dataset\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "     \n",
    "        yhat=yhat.reshape(-1)\n",
    "\n",
    "        # Calculating Mean Sum of squared error\n",
    "        mse=1/len(yhat)*sum(np.square(y_input-yhat))\n",
    "        mse\n",
    "\n",
    "        #95% Confidence Interval at alpha=0.05, zalpha/2=1.96\n",
    "        yhat_b = 1/len(yhat)*sum(yhat)\n",
    "        ieta = np.sqrt(1/len(yhat)*sum(np.square(yhat-yhat_b)))\n",
    "        CI_L = yhat_b-1.96*ieta\n",
    "        CI_U = yhat_b+1.96*ieta\n",
    "\n",
    "        # Confidence Prediction at each step points\n",
    "        import matplotlib.pyplot as plt\n",
    "        y_l=yhat-1.96*ieta\n",
    "        y_u=yhat+1.96*ieta\n",
    "\n",
    "\n",
    "        \n",
    "        print('RMSE',np.sqrt(mse))\n",
    "        rmse.append(np.sqrt(mse))\n",
    "        print('Confidence Interval :', CI_L , CI_U)\n",
    "        cfu.append(CI_U)\n",
    "        cfl.append(CI_L)\n",
    "        \n",
    "result=pd.DataFrame({'RMSE':rmse,'CI_U':cfu,'CI_L':cfl,'nsteps':nsteps})\n",
    "result.to_csv('Stackedlstm_DH_sensitivity'+'n_step_.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Malancha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Malanchafrom numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "rmse = []\n",
    "cfu= []\n",
    "cfl= []\n",
    "nsteps = []\n",
    "for j in [3,5,7,9]:\n",
    "    for i in range(20):\n",
    "        nsteps.append(j)\n",
    "        # Defining a function to split a univariate sequence into samples for LSTM Model\n",
    "        def split_sequence(sequence, n_steps):\n",
    "            X, y = list(), list()\n",
    "            for i in range(len(sequence)):\n",
    "                # find the end of this pattern\n",
    "                end_ix = i + n_steps\n",
    "                # check if we are beyond the sequence\n",
    "                if end_ix > len(sequence)-1:\n",
    "                    break\n",
    "                # gather input and output parts of the pattern\n",
    "                seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "                X.append(seq_x)\n",
    "                y.append(seq_y)\n",
    "            return array(X), array(y)\n",
    "\n",
    "        # define input sequence\n",
    "        data=pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet2')\n",
    "\n",
    "        tdw=pd.Series([2016])\n",
    "        train_data=data[~data['Year '].isin(tdw)]\n",
    "        test_data=data[data['Year '].isin(tdw)]\n",
    "        test_data=test_data.set_index(np.arange(0,len(test_data)))\n",
    "        n_steps = j\n",
    "        # split into samples\n",
    "        X, y = split_sequence(train_data.Value, n_steps)\n",
    "        # reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "        n_features = 1\n",
    "        X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "        model.add(LSTM(50, activation='relu'))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        # fit model\n",
    "        model.fit(X, y, epochs=200, verbose=0)\n",
    "        # demonstrate prediction\n",
    "        # split into samples\n",
    "        x_input, y_input = split_sequence(test_data.Value, n_steps)\n",
    "\n",
    "        x_input = x_input.reshape((x_input.shape[0], x_input.shape[1], n_features))\n",
    "\n",
    "        #Prediction on Test dataset\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "\n",
    "        yhat=yhat.reshape(-1)\n",
    "\n",
    "        # Calculating Mean Sum of squared error\n",
    "        mse=1/len(yhat)*sum(np.square(y_input-yhat))\n",
    "        mse\n",
    "\n",
    "        #95% Confidence Interval at alpha=0.05, zalpha/2=1.96\n",
    "        yhat_b = 1/len(yhat)*sum(yhat)\n",
    "        ieta = np.sqrt(1/len(yhat)*sum(np.square(yhat-yhat_b)))\n",
    "        CI_L = yhat_b-1.96*ieta\n",
    "        CI_U = yhat_b+1.96*ieta\n",
    "\n",
    "        # Confidence Prediction at each step points\n",
    "        import matplotlib.pyplot as plt\n",
    "        y_l=yhat-1.96*ieta\n",
    "        y_u=yhat+1.96*ieta\n",
    "\n",
    "\n",
    "        \n",
    "        print('RMSE',np.sqrt(mse))\n",
    "        rmse.append(np.sqrt(mse))\n",
    "        print('Confidence Interval :', CI_L , CI_U)\n",
    "        cfu.append(CI_U)\n",
    "        cfl.append(CI_L)\n",
    "        \n",
    "result=pd.DataFrame({'RMSE':rmse,'CI_U':cfu,'CI_L':cfl,'nsteps':nsteps})\n",
    "result.to_csv('Stackedlstm_M_sensitivity'+'n_step_.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raidighi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Raidighifrom numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "rmse = []\n",
    "cfu= []\n",
    "cfl= []\n",
    "nsteps = []\n",
    "for j in [3,5,7,9]:\n",
    "    for i in range(20):\n",
    "        nsteps.append(j)\n",
    "        # Defining a function to split a univariate sequence into samples for LSTM Model\n",
    "        def split_sequence(sequence, n_steps):\n",
    "            X, y = list(), list()\n",
    "            for i in range(len(sequence)):\n",
    "                # find the end of this pattern\n",
    "                end_ix = i + n_steps\n",
    "                # check if we are beyond the sequence\n",
    "                if end_ix > len(sequence)-1:\n",
    "                    break\n",
    "                # gather input and output parts of the pattern\n",
    "                seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "                X.append(seq_x)\n",
    "                y.append(seq_y)\n",
    "            return array(X), array(y)\n",
    "\n",
    "        # define input sequence\n",
    "        data=pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet3')\n",
    "\n",
    "        tdw=pd.Series([2016])\n",
    "        train_data=data[~data['Year '].isin(tdw)]\n",
    "        test_data=data[data['Year '].isin(tdw)]\n",
    "        test_data=test_data.set_index(np.arange(0,len(test_data)))\n",
    "        n_steps = j\n",
    "        # split into samples\n",
    "        X, y = split_sequence(train_data.Value, n_steps)\n",
    "        # reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "        n_features = 1\n",
    "        X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "        model.add(LSTM(50, activation='relu'))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        # fit model\n",
    "        model.fit(X, y, epochs=200, verbose=0)\n",
    "        # demonstrate prediction\n",
    "        # split into samples\n",
    "        x_input, y_input = split_sequence(test_data.Value, n_steps)\n",
    "\n",
    "        x_input = x_input.reshape((x_input.shape[0], x_input.shape[1], n_features))\n",
    "\n",
    "        #Prediction on Test dataset\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "    \n",
    "        yhat=yhat.reshape(-1)\n",
    "\n",
    "        # Calculating Mean Sum of squared error\n",
    "        mse=1/len(yhat)*sum(np.square(y_input-yhat))\n",
    "        mse\n",
    "\n",
    "        #95% Confidence Interval at alpha=0.05, zalpha/2=1.96\n",
    "        yhat_b = 1/len(yhat)*sum(yhat)\n",
    "        ieta = np.sqrt(1/len(yhat)*sum(np.square(yhat-yhat_b)))\n",
    "        CI_L = yhat_b-1.96*ieta\n",
    "        CI_U = yhat_b+1.96*ieta\n",
    "\n",
    "        # Confidence Prediction at each step points\n",
    "        import matplotlib.pyplot as plt\n",
    "        y_l=yhat-1.96*ieta\n",
    "        y_u=yhat+1.96*ieta\n",
    "\n",
    "\n",
    "        \n",
    "        print('RMSE',np.sqrt(mse))\n",
    "        rmse.append(np.sqrt(mse))\n",
    "        print('Confidence Interval :', CI_L , CI_U)\n",
    "        cfu.append(CI_U)\n",
    "        cfl.append(CI_L)\n",
    "        \n",
    "result=pd.DataFrame({'RMSE':rmse,'CI_U':cfu,'CI_L':cfl,'nsteps':nsteps})\n",
    "result.to_csv('Stackedlstm_R_sensitivity'+'n_step_.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diamond Harbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Diamond Harbourfrom numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Bidirectional\n",
    "rmse = []\n",
    "cfu= []\n",
    "cfl= []\n",
    "nsteps = []\n",
    "for j in [3,5,7,9]:\n",
    "    for i in range(20):\n",
    "        nsteps.append(j)\n",
    "        # Defining a function to split a univariate sequence into samples for LSTM Model\n",
    "        def split_sequence(sequence, n_steps):\n",
    "            X, y = list(), list()\n",
    "            for i in range(len(sequence)):\n",
    "                # find the end of this pattern\n",
    "                end_ix = i + n_steps\n",
    "                # check if we are beyond the sequence\n",
    "                if end_ix > len(sequence)-1:\n",
    "                    break\n",
    "                # gather input and output parts of the pattern\n",
    "                seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "                X.append(seq_x)\n",
    "                y.append(seq_y)\n",
    "            return array(X), array(y)\n",
    "\n",
    "        # define input sequence\n",
    "        data=pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "        tdw=pd.Series([2016])\n",
    "        train_data=data[~data['Year '].isin(tdw)]\n",
    "        test_data=data[data['Year '].isin(tdw)]\n",
    "        test_data=test_data.set_index(np.arange(0,len(test_data)))\n",
    "        n_steps = j\n",
    "        # split into samples\n",
    "        X, y = split_sequence(train_data.Value, n_steps)\n",
    "        # reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "        n_features = 1\n",
    "        X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        # fit model\n",
    "        model.fit(X, y, epochs=200, verbose=0)\n",
    "        # demonstrate prediction\n",
    "\n",
    "        x_input, y_input = split_sequence(test_data.Value, n_steps)\n",
    "\n",
    "      \n",
    "        x_input = x_input.reshape((x_input.shape[0], x_input.shape[1], n_features))\n",
    "\n",
    "        #Prediction on Test dataset\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "  \n",
    "        yhat=yhat.reshape(-1)\n",
    "\n",
    "        # Calculating Mean Sum of squared error\n",
    "        mse=1/len(yhat)*sum(np.square(y_input-yhat))\n",
    "        mse\n",
    "\n",
    "        #95% Confidence Interval at alpha=0.05, zalpha/2=1.96\n",
    "        yhat_b = 1/len(yhat)*sum(yhat)\n",
    "        ieta = np.sqrt(1/len(yhat)*sum(np.square(yhat-yhat_b)))\n",
    "        CI_L = yhat_b-1.96*ieta\n",
    "        CI_U = yhat_b+1.96*ieta\n",
    "\n",
    "        # Confidence Prediction at each step points\n",
    "        import matplotlib.pyplot as plt\n",
    "        y_l=yhat-1.96*ieta\n",
    "        y_u=yhat+1.96*ieta\n",
    "\n",
    "\n",
    "        \n",
    "        print('RMSE',np.sqrt(mse))\n",
    "        rmse.append(np.sqrt(mse))\n",
    "        print('Confidence Interval :', CI_L , CI_U)\n",
    "        cfu.append(CI_U)\n",
    "        cfl.append(CI_L)\n",
    "        \n",
    "result=pd.DataFrame({'RMSE':rmse,'CI_U':cfu,'CI_L':cfl,'nsteps':nsteps})\n",
    "result.to_csv('Bidirectional_DH_sensitivity'+'n_step_.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Malancha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Malanchafrom numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Bidirectional\n",
    "rmse = []\n",
    "cfu= []\n",
    "cfl= []\n",
    "nsteps = []\n",
    "for j in [3,5,7,9]:\n",
    "    for i in range(20):\n",
    "        nsteps.append(j)\n",
    "        # Defining a function to split a univariate sequence into samples for LSTM Model\n",
    "        def split_sequence(sequence, n_steps):\n",
    "            X, y = list(), list()\n",
    "            for i in range(len(sequence)):\n",
    "                # find the end of this pattern\n",
    "                end_ix = i + n_steps\n",
    "                # check if we are beyond the sequence\n",
    "                if end_ix > len(sequence)-1:\n",
    "                    break\n",
    "                # gather input and output parts of the pattern\n",
    "                seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "                X.append(seq_x)\n",
    "                y.append(seq_y)\n",
    "            return array(X), array(y)\n",
    "\n",
    "        # define input sequence\n",
    "        data=pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet2')\n",
    "\n",
    "        tdw=pd.Series([2016])\n",
    "        train_data=data[~data['Year '].isin(tdw)]\n",
    "        test_data=data[data['Year '].isin(tdw)]\n",
    "        test_data=test_data.set_index(np.arange(0,len(test_data)))\n",
    "        n_steps = j\n",
    "        # split into samples\n",
    "        X, y = split_sequence(train_data.Value, n_steps)\n",
    "        # reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "        n_features = 1\n",
    "        X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        # fit model\n",
    "        model.fit(X, y, epochs=200, verbose=0)\n",
    "        # demonstrate prediction\n",
    "\n",
    "        x_input, y_input = split_sequence(test_data.Value, n_steps)\n",
    "\n",
    "       \n",
    "        x_input = x_input.reshape((x_input.shape[0], x_input.shape[1], n_features))\n",
    "\n",
    "         #Prediction on Test dataset\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "\n",
    "        yhat=yhat.reshape(-1)\n",
    "\n",
    "        # Calculating Mean Sum of squared error\n",
    "        mse=1/len(yhat)*sum(np.square(y_input-yhat))\n",
    "        mse\n",
    "\n",
    "        #95% Confidence Interval at alpha=0.05, zalpha/2=1.96\n",
    "        yhat_b = 1/len(yhat)*sum(yhat)\n",
    "        ieta = np.sqrt(1/len(yhat)*sum(np.square(yhat-yhat_b)))\n",
    "        CI_L = yhat_b-1.96*ieta\n",
    "        CI_U = yhat_b+1.96*ieta\n",
    "\n",
    "        # Confidence Prediction at each step points\n",
    "        import matplotlib.pyplot as plt\n",
    "        y_l=yhat-1.96*ieta\n",
    "        y_u=yhat+1.96*ieta\n",
    "\n",
    "\n",
    "        \n",
    "        print('RMSE',np.sqrt(mse))\n",
    "        rmse.append(np.sqrt(mse))\n",
    "        print('Confidence Interval :', CI_L , CI_U)\n",
    "        cfu.append(CI_U)\n",
    "        cfl.append(CI_L)\n",
    "        \n",
    "result=pd.DataFrame({'RMSE':rmse,'CI_U':cfu,'CI_L':cfl,'nsteps':nsteps})\n",
    "result.to_csv('Bidirectional_M_sensitivity'+'n_step_.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raidighi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Raidighifrom numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Bidirectional\n",
    "rmse = []\n",
    "cfu= []\n",
    "cfl= []\n",
    "nsteps = []\n",
    "for j in [3,5,7,9]:\n",
    "    for i in range(20):\n",
    "        nsteps.append(j)\n",
    "        # Defining a function to split a univariate sequence into samples for LSTM Model\n",
    "        def split_sequence(sequence, n_steps):\n",
    "            X, y = list(), list()\n",
    "            for i in range(len(sequence)):\n",
    "                # find the end of this pattern\n",
    "                end_ix = i + n_steps\n",
    "                # check if we are beyond the sequence\n",
    "                if end_ix > len(sequence)-1:\n",
    "                    break\n",
    "                # gather input and output parts of the pattern\n",
    "                seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "                X.append(seq_x)\n",
    "                y.append(seq_y)\n",
    "            return array(X), array(y)\n",
    "\n",
    "        # define input sequence\n",
    "        data=pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet3')\n",
    "\n",
    "        tdw=pd.Series([2016])\n",
    "        train_data=data[~data['Year '].isin(tdw)]\n",
    "        test_data=data[data['Year '].isin(tdw)]\n",
    "        test_data=test_data.set_index(np.arange(0,len(test_data)))\n",
    "        n_steps = j\n",
    "        # split into samples\n",
    "        X, y = split_sequence(train_data.Value, n_steps)\n",
    "        # reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "        n_features = 1\n",
    "        X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        # fit model\n",
    "        model.fit(X, y, epochs=200, verbose=0)\n",
    "        # demonstrate prediction\n",
    "\n",
    "        x_input, y_input = split_sequence(test_data.Value, n_steps)\n",
    "\n",
    "        x_input = x_input.reshape((x_input.shape[0], x_input.shape[1], n_features))\n",
    "\n",
    "         #Prediction on Test dataset\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "   \n",
    "        yhat=yhat.reshape(-1)\n",
    "\n",
    "        # Calculating Mean Sum of squared error\n",
    "        mse=1/len(yhat)*sum(np.square(y_input-yhat))\n",
    "        mse\n",
    "\n",
    "        #95% Confidence Interval at alpha=0.05, zalpha/2=1.96\n",
    "        yhat_b = 1/len(yhat)*sum(yhat)\n",
    "        ieta = np.sqrt(1/len(yhat)*sum(np.square(yhat-yhat_b)))\n",
    "        CI_L = yhat_b-1.96*ieta\n",
    "        CI_U = yhat_b+1.96*ieta\n",
    "\n",
    "        # Confidence Prediction at each step points\n",
    "        import matplotlib.pyplot as plt\n",
    "        y_l=yhat-1.96*ieta\n",
    "        y_u=yhat+1.96*ieta\n",
    "\n",
    "\n",
    "        \n",
    "        print('RMSE',np.sqrt(mse))\n",
    "        rmse.append(np.sqrt(mse))\n",
    "        print('Confidence Interval :', CI_L , CI_U)\n",
    "        cfu.append(CI_U)\n",
    "        cfl.append(CI_L)\n",
    "        \n",
    "result=pd.DataFrame({'RMSE':rmse,'CI_U':cfu,'CI_L':cfl,'nsteps':nsteps})\n",
    "result.to_csv('Bidirectional_R_sensitivity'+'n_step_.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diamond Harbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Diamond Harbourfrom numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "rmse = []\n",
    "cfu= []\n",
    "cfl= []\n",
    "nsteps = []\n",
    "for j in [4,6,8,10]:\n",
    "    for i in range(20):\n",
    "        nsteps.append(j)\n",
    "        # Defining a function to split a univariate sequence into samples for LSTM Model\n",
    "        def split_sequence(sequence, n_steps):\n",
    "            X, y = list(), list()\n",
    "            for i in range(len(sequence)):\n",
    "                # find the end of this pattern\n",
    "                end_ix = i + n_steps\n",
    "                # check if we are beyond the sequence\n",
    "                if end_ix > len(sequence)-1:\n",
    "                    break\n",
    "                # gather input and output parts of the pattern\n",
    "                seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "                X.append(seq_x)\n",
    "                y.append(seq_y)\n",
    "            return array(X), array(y)\n",
    "\n",
    "        # define input sequence\n",
    "        data=pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "        tdw=pd.Series([2016])\n",
    "        train_data=data[~data['Year '].isin(tdw)]\n",
    "        test_data=data[data['Year '].isin(tdw)]\n",
    "        test_data=test_data.set_index(np.arange(0,len(test_data)))\n",
    "        \n",
    "        \n",
    "        n_step1 = j\n",
    "        # split into samples\n",
    "        X, y = split_sequence(train_data.Value, n_step1)\n",
    "        # reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
    "        n_features = 1\n",
    "        n_seq = 2\n",
    "        n_step2 = int(n_step1/2)\n",
    "        X = X.reshape((X.shape[0], n_seq, n_step2, n_features))\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, n_step2, n_features)))\n",
    "        model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        model.add(LSTM(50, activation='relu'))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        # fit model\n",
    "        model.fit(X, y, epochs=500, verbose=0)\n",
    "        # demonstrate prediction\n",
    "        x_input, y_input = split_sequence(test_data.Value, n_step1)\n",
    "\n",
    "        x_input = x_input.reshape((x_input.shape[0], n_seq, n_step2, n_features))\n",
    "\n",
    "         #Prediction on Test dataset\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "      \n",
    "        yhat=yhat.reshape(-1)\n",
    "\n",
    "        # Calculating Mean Sum of squared error\n",
    "        mse=1/len(yhat)*sum(np.square(y_input-yhat))\n",
    "        mse\n",
    "\n",
    "        #95% Confidence Interval at alpha=0.05, zalpha/2=1.96\n",
    "        yhat_b = 1/len(yhat)*sum(yhat)\n",
    "        ieta = np.sqrt(1/len(yhat)*sum(np.square(yhat-yhat_b)))\n",
    "        CI_L = yhat_b-1.96*ieta\n",
    "        CI_U = yhat_b+1.96*ieta\n",
    "\n",
    "        # Confidence Prediction at each step points\n",
    "        import matplotlib.pyplot as plt\n",
    "        y_l=yhat-1.96*ieta\n",
    "        y_u=yhat+1.96*ieta\n",
    "\n",
    "\n",
    "        \n",
    "        print('RMSE',np.sqrt(mse))\n",
    "        rmse.append(np.sqrt(mse))\n",
    "        print('Confidence Interval :', CI_L , CI_U)\n",
    "        cfu.append(CI_U)\n",
    "        cfl.append(CI_L)\n",
    "        \n",
    "result=pd.DataFrame({'RMSE':rmse,'CI_U':cfu,'CI_L':cfl,'nsteps':nsteps})\n",
    "result.to_csv('CNN_DH_sensitivity'+'n_step_.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Malancha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Malanchafrom numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "rmse = []\n",
    "cfu= []\n",
    "cfl= []\n",
    "nsteps = []\n",
    "for j in [4,6,8,10]:\n",
    "    for i in range(20):\n",
    "        nsteps.append(j)\n",
    "        # Defining a function to split a univariate sequence into samples for LSTM Model\n",
    "        def split_sequence(sequence, n_steps):\n",
    "            X, y = list(), list()\n",
    "            for i in range(len(sequence)):\n",
    "                # find the end of this pattern\n",
    "                end_ix = i + n_steps\n",
    "                # check if we are beyond the sequence\n",
    "                if end_ix > len(sequence)-1:\n",
    "                    break\n",
    "                # gather input and output parts of the pattern\n",
    "                seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "                X.append(seq_x)\n",
    "                y.append(seq_y)\n",
    "            return array(X), array(y)\n",
    "\n",
    "        # define input sequence\n",
    "        data=pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet2')\n",
    "\n",
    "        tdw=pd.Series([2016])\n",
    "        train_data=data[~data['Year '].isin(tdw)]\n",
    "        test_data=data[data['Year '].isin(tdw)]\n",
    "        test_data=test_data.set_index(np.arange(0,len(test_data)))\n",
    "        \n",
    "        \n",
    "        n_step1 = j\n",
    "        # split into samples\n",
    "        X, y = split_sequence(train_data.Value, n_step1)\n",
    "        # reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
    "        n_features = 1\n",
    "        n_seq = 2\n",
    "        n_step2 = int(n_step1/2)\n",
    "        X = X.reshape((X.shape[0], n_seq, n_step2, n_features))\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, n_step2, n_features)))\n",
    "        model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        model.add(LSTM(50, activation='relu'))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        # fit model\n",
    "        model.fit(X, y, epochs=500, verbose=0)\n",
    "        # demonstrate prediction\n",
    "        x_input, y_input = split_sequence(test_data.Value, n_step1)\n",
    "\n",
    "  \n",
    "        x_input = x_input.reshape((x_input.shape[0], n_seq, n_step2, n_features))\n",
    "\n",
    "         #Prediction on Test dataset\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "     \n",
    "        yhat=yhat.reshape(-1)\n",
    "\n",
    "        # Calculating Mean Sum of squared error\n",
    "        mse=1/len(yhat)*sum(np.square(y_input-yhat))\n",
    "        mse\n",
    "\n",
    "        #95% Confidence Interval at alpha=0.05, zalpha/2=1.96\n",
    "        yhat_b = 1/len(yhat)*sum(yhat)\n",
    "        ieta = np.sqrt(1/len(yhat)*sum(np.square(yhat-yhat_b)))\n",
    "        CI_L = yhat_b-1.96*ieta\n",
    "        CI_U = yhat_b+1.96*ieta\n",
    "\n",
    "        # Confidence Prediction at each step points\n",
    "        import matplotlib.pyplot as plt\n",
    "        y_l=yhat-1.96*ieta\n",
    "        y_u=yhat+1.96*ieta\n",
    "\n",
    "\n",
    "        \n",
    "        print('RMSE',np.sqrt(mse))\n",
    "        rmse.append(np.sqrt(mse))\n",
    "        print('Confidence Interval :', CI_L , CI_U)\n",
    "        cfu.append(CI_U)\n",
    "        cfl.append(CI_L)\n",
    "        \n",
    "result=pd.DataFrame({'RMSE':rmse,'CI_U':cfu,'CI_L':cfl,'nsteps':nsteps})\n",
    "result.to_csv('CNN_M_sensitivity'+'n_step_.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raidighi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "rmse = []\n",
    "cfu= []\n",
    "cfl= []\n",
    "nsteps = []\n",
    "for j in [4,6,8,10]:\n",
    "    for i in range(20):\n",
    "        nsteps.append(j)\n",
    "        # Defining a function to split a univariate sequence into samples for LSTM Model\n",
    "        def split_sequence(sequence, n_steps):\n",
    "            X, y = list(), list()\n",
    "            for i in range(len(sequence)):\n",
    "                # find the end of this pattern\n",
    "                end_ix = i + n_steps\n",
    "                # check if we are beyond the sequence\n",
    "                if end_ix > len(sequence)-1:\n",
    "                    break\n",
    "                # gather input and output parts of the pattern\n",
    "                seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "                X.append(seq_x)\n",
    "                y.append(seq_y)\n",
    "            return array(X), array(y)\n",
    "\n",
    "        # define input sequence\n",
    "        data=pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet3')\n",
    "\n",
    "        tdw=pd.Series([2016])\n",
    "        train_data=data[~data['Year '].isin(tdw)]\n",
    "        test_data=data[data['Year '].isin(tdw)]\n",
    "        test_data=test_data.set_index(np.arange(0,len(test_data)))\n",
    "        \n",
    "        \n",
    "        n_step1 = j\n",
    "        # split into samples\n",
    "        X, y = split_sequence(train_data.Value, n_step1)\n",
    "        # reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
    "        n_features = 1\n",
    "        n_seq = 2\n",
    "        n_step2 = int(n_step1/2)\n",
    "        X = X.reshape((X.shape[0], n_seq, n_step2, n_features))\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, n_step2, n_features)))\n",
    "        model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        model.add(LSTM(50, activation='relu'))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        # fit model\n",
    "        model.fit(X, y, epochs=500, verbose=0)\n",
    "        # demonstrate prediction\n",
    "        x_input, y_input = split_sequence(test_data.Value, n_step1)\n",
    "\n",
    "        x_input = x_input.reshape((x_input.shape[0], n_seq, n_step2, n_features))\n",
    "\n",
    "         #Prediction on Test dataset\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "       \n",
    "        yhat=yhat.reshape(-1)\n",
    "\n",
    "        # Calculating Mean Sum of squared error\n",
    "        mse=1/len(yhat)*sum(np.square(y_input-yhat))\n",
    "        mse\n",
    "\n",
    "        #95% Confidence Interval at alpha=0.05, zalpha/2=1.96\n",
    "        yhat_b = 1/len(yhat)*sum(yhat)\n",
    "        ieta = np.sqrt(1/len(yhat)*sum(np.square(yhat-yhat_b)))\n",
    "        CI_L = yhat_b-1.96*ieta\n",
    "        CI_U = yhat_b+1.96*ieta\n",
    "\n",
    "        # Confidence Prediction at each step points\n",
    "        import matplotlib.pyplot as plt\n",
    "        y_l=yhat-1.96*ieta\n",
    "        y_u=yhat+1.96*ieta\n",
    "\n",
    "\n",
    "        \n",
    "        print('RMSE',np.sqrt(mse))\n",
    "        rmse.append(np.sqrt(mse))\n",
    "        print('Confidence Interval :', CI_L , CI_U)\n",
    "        cfu.append(CI_U)\n",
    "        cfl.append(CI_L)\n",
    "        \n",
    "result=pd.DataFrame({'RMSE':rmse,'CI_U':cfu,'CI_L':cfl,'nsteps':nsteps})\n",
    "result.to_csv('CNN_R_sensitivity'+'n_step_.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = ['M','R','DH']\n",
    "i=0\n",
    "Data=['Convlstm_',\n",
    "      'Stackedlstm_',\n",
    "      'Vanillalstm_',\n",
    "      'Bidirectional_',\n",
    "      'CNN_']\n",
    "for j in range(len(Data)):\n",
    "    for i in range(len(site)):\n",
    "        file = Data[j] + site[i]+'_sensitivityn_step_.csv'\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.2.4 Figure 7 (In manuscript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "site = ['M','DH','R']\n",
    "color = ['red','green','blue']\n",
    "name = ['Malancha','Diamond Harbour','Raidighi']\n",
    "title = ['Conv LSTM','Stacked LSTM','Vanilla LSTM','Bidirectional LSTM','CNN LSTM']\n",
    "img = ['(a)','(b)','(c)','(d)','(e)']\n",
    "Data=['Convlstm_',\n",
    "      'Stackedlstm_',\n",
    "      'Vanillalstm_',\n",
    "      'Bidirectional_',\n",
    "      'CNN_']\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')\n",
    "fig = plt.figure(figsize=(12,10))\n",
    "for j in range(len(Data)):\n",
    "    ndata = pd.DataFrame()\n",
    "    for i in range(len(site)):\n",
    "        file = Data[j] + site[i]+'_sensitivityn_step_.csv'\n",
    "        data = pd.read_csv(file)\n",
    "        data['site']= np.repeat(name[i],len(data))\n",
    "        ndata = ndata.append(data)\n",
    "    axes=fig.add_subplot(2, 3, j+1)\n",
    "    sns.pointplot(data=ndata, x=\"nsteps\", y=\"RMSE\", hue='site', ax=axes)\n",
    "    axes.set_ylabel('Root Mean Square Error', size=12)\n",
    "    axes.set_xlabel('Input Time Step', size=12)\n",
    "    axes.set_title(img[j]+' '+title[j], size=14.5)\n",
    "    axes.legend(loc='best', fontsize=10)\n",
    "    plt.yticks([2,4,6,8,10,12,14,16,18])\n",
    "plt.tight_layout()\n",
    "plt.savefig('Sensitivity_analysis_all.jpg', dpi=400)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
