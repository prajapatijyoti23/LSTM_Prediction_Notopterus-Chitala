{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Forecasting Population of Chitala Fish from Catch Data for next 10 Years using Best Models for each site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import ConvLSTM2D\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model for site1-Diamond harbour : Convlstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import ConvLSTM2D\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Defining a function to split a univariate sequence into samples for LSTM Model\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "\n",
    "# define input sequence\n",
    "data=pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "tdw=pd.Series([2016])\n",
    "train_data=data[~data['Year '].isin(tdw)]\n",
    "test_data=data[data['Year '].isin(tdw)]\n",
    "test_data=test_data.set_index(np.arange(0,len(test_data)))\n",
    "n_step1 = 4\n",
    "# split into samples\n",
    "X, y = split_sequence(data.Value, n_step1)\n",
    "\n",
    "n_features = 1\n",
    "n_seq = 2\n",
    "n_step2 = int(n_step1/2)\n",
    "X = X.reshape((X.shape[0], n_seq, 1, n_step2, n_features))\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu', input_shape=(n_seq, 1, n_step2, n_features)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=500, verbose=0)\n",
    "# demonstrate prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=1ypr=[]\n",
    "yr=9*12\n",
    "x=data.Value.iloc[36:].values\n",
    "i=0\n",
    "for k in range(yr):\n",
    "    x_input, y_input = split_sequence(x, n_step1)\n",
    "            #x_input = array([70, 80, 90])\n",
    "    x_input = x_input.reshape((x_input.shape[0], n_seq,1, n_step2, n_features))\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    x = np.append(x,yhat)\n",
    "    x=x[8:]\n",
    "    ypr.append(yhat.reshape(-1)[0])\n",
    "yer=np.repeat(np.arange(2016,2025),12)\n",
    "pred = pd.DataFrame({'Year':yer,'Future_prediction':ypr}) \n",
    "pred.to_csv('Bestmodel_convlstm_DH.csv')\n",
    "valu=[]\n",
    "year = np.arange(2016,2025)\n",
    "for i in range(len(year)):\n",
    "    val = pred[pred['Year']==year[i]]['Future_prediction'].mean()\n",
    "    valu.append(val)\n",
    "mean_pred=pd.DataFrame({'Year':year,'Mean_prediction':valu})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = pd.read_csv('Bestmodel_convlstm_DH.csv')\n",
    "old = pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet1')\n",
    "old = pd.DataFrame({'Year':old['Year '][0:36],'Future_prediction':old['Value'][0:36]})\n",
    "old=old.append(best[['Year','Future_prediction']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model for site2-Malancha : CNN lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Defining a function to split a univariate sequence into samples for LSTM Model\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "\n",
    "# define input sequence\n",
    "data=pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet2')\n",
    "\n",
    "tdw=pd.Series([2016])\n",
    "train_data=data[~data['Year '].isin(tdw)]\n",
    "test_data=data[data['Year '].isin(tdw)]\n",
    "test_data=test_data.set_index(np.arange(0,len(test_data)))\n",
    "\n",
    "n_step1 = 10\n",
    "# split into samples\n",
    "X, y = split_sequence(train_data.Value, n_step1)\n",
    "# reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
    "n_features = 1\n",
    "n_seq = 2\n",
    "n_step2 = int(n_step1/2)\n",
    "X = X.reshape((X.shape[0], n_seq, n_step2, n_features))\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, n_step2, n_features)))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=500, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input, y_input = split_sequence(test_data.Value, n_step1)\n",
    "\n",
    "x_input = x_input.reshape((x_input.shape[0], n_seq, n_step2, n_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypr=[]\n",
    "yr=9*6\n",
    "x=data.Value.iloc[36:].values\n",
    "i=0\n",
    "for k in range(yr):\n",
    "    x_input, y_input = split_sequence(x, n_step1)\n",
    "    x_input = x_input.reshape((x_input.shape[0], n_seq, n_step2, n_features))\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    x=np.append(x, yhat)\n",
    "    x=x[2:]\n",
    "    ypr=np.append(ypr,yhat.reshape(-1))\n",
    "yer=np.repeat(np.arange(2016,2025),12)\n",
    "pred = pd.DataFrame({'Year':yer,'Future_prediction':ypr}) \n",
    "pred.to_csv('Bestmodel_CNNlstm_M.csv')\n",
    "valu=[]\n",
    "year = np.arange(2016,2025)\n",
    "for i in range(len(year)):\n",
    "    val = pred[pred['Year']==year[i]]['Future_prediction'].mean()\n",
    "    valu.append(val)\n",
    "mean_pred=pd.DataFrame({'Year':year,'Mean_prediction':valu})\n",
    "mean_pred.to_csv('mean_Bestmodel_CNNlstm_M.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_csv('Bestmodel_vanillalstm_site2.csv')\n",
    "valu=[]\n",
    "year = np.arange(2016,2025)\n",
    "for i in range(len(year)):\n",
    "    val = pred[pred['Year']==year[i]]['Future_prediction'].mean()\n",
    "    valu.append(val)\n",
    "mean_pred=pd.DataFrame({'Year':year,'Mean_prediction':valu})\n",
    "mean_pred.to_csv('mean_Bestmodel_vanillalstm_site2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = pd.read_csv('Bestmodel_CNNlstm_M.csv')\n",
    "old = pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet2')\n",
    "old = pd.DataFrame({'Year':old['Year '][0:36],'Future_prediction':old['Value'][0:36]})\n",
    "old=old.append(best[['Year','Future_prediction']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model for site3-Raidighi : Bidirectional lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Bidirectional\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Defining a function to split a univariate sequence into samples for LSTM Model\n",
    "\n",
    "# Defining a function to split a univariate sequence into samples for LSTM Model\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "\n",
    "# define input sequence\n",
    "data=pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet3')\n",
    "\n",
    "tdw=pd.Series([2016])\n",
    "train_data=data[~data['Year '].isin(tdw)]\n",
    "test_data=data[data['Year '].isin(tdw)]\n",
    "test_data=test_data.set_index(np.arange(0,len(test_data)))\n",
    "n_steps = 7\n",
    "# split into samples\n",
    "X, y = split_sequence(train_data.Value, n_steps)\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "# demonstrate prediction\n",
    "\n",
    "x_input, y_input = split_sequence(test_data.Value, n_steps)\n",
    "\n",
    "x_input = x_input.reshape((x_input.shape[0], x_input.shape[1], n_features))\n",
    "\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "yhat=yhat.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypr=[]\n",
    "yr=22\n",
    "x=data.Value.iloc[36:].values\n",
    "i=0\n",
    "for k in range(yr):\n",
    "    x_input, y_input = split_sequence(x, n_steps)\n",
    "    x_input = x_input.reshape((x_input.shape[0], x_input.shape[1], n_features))\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    x=np.append(x, yhat)\n",
    "    x=x[5:]\n",
    "    ypr=np.append(ypr,yhat.reshape(-1))\n",
    "    #print(x, len(x))\n",
    "yer=np.repeat(np.arange(2016,2025),12)\n",
    "pred = pd.DataFrame({'Year':yer,'Future_prediction':ypr[:-2]}) \n",
    "pred.to_csv('Bestmodel_Bidirectionallstm_R.csv')\n",
    "valu=[]\n",
    "year = np.arange(2016,2025)\n",
    "for i in range(len(year)):\n",
    "    val = pred[pred['Year']==year[i]]['Future_prediction'].mean()\n",
    "    valu.append(val)\n",
    "mean_pred=pd.DataFrame({'Year':year,'Mean_prediction':valu})\n",
    "mean_pred.to_csv('mean_Bestmodel_Bidirectionallstm_R.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = pd.read_csv('Bestmodel_Bidirectionallstm_R.csv')\n",
    "old = pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet3')\n",
    "old = pd.DataFrame({'Year':old['Year '][0:36],'Future_prediction':old['Value'][0:36]})\n",
    "old=old.append(best[['Year','Future_prediction']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined plots of three sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best3 = pd.read_csv('Bestmodel_Bidirectionallstm_R.csv')\n",
    "old3 = pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet3')\n",
    "old3 = pd.DataFrame({'Year':old3['Year '][0:36],'Future_prediction':old3['Value'][0:36]})\n",
    "old3=old3.append(best3[['Year','Future_prediction']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best2 = pd.read_csv('Bestmodel_CNNlstm_M.csv')\n",
    "old2 = pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet2')\n",
    "old2 = pd.DataFrame({'Year':old2['Year '][0:36],'Future_prediction':old2['Value'][0:36]})\n",
    "old2=old2.append(best2[['Year','Future_prediction']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best1 = pd.read_csv('Bestmodel_convlstm_DH.csv')\n",
    "old1 = pd.read_excel('Chitala_TS.xlsx', sheet_name='Sheet1')\n",
    "old1 = pd.DataFrame({'Year':old1['Year '][0:36],'Future_prediction':old1['Value'][0:36]})\n",
    "old1=old1.append(best1[['Year','Future_prediction']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat3=old3['Future_prediction'].values\n",
    "yhat3_b = 1/len(yhat3)*sum(yhat3)\n",
    "ieta3 = np.sqrt(1/len(yhat3)*sum(np.square(yhat3-yhat3_b)))\n",
    "ieta3\n",
    "\n",
    "ieta3\n",
    "CI_L3 = yhat3_b-1.96*ieta3\n",
    "CI_U3 = yhat3_b+1.96*ieta3\n",
    "import matplotlib.pyplot as plt\n",
    "y_l3=yhat3-1.96*ieta3\n",
    "y_u3=yhat3+1.96*ieta3\n",
    "Months=range(0,len(yhat3))\n",
    "plt.subplots(figsize=(15,6))\n",
    "\n",
    "plt.plot(yhat3.reshape(-1), label='Future prediction')\n",
    "plt.plot(y_l3, label='pred_95', c='red', linestyle='--', alpha=0.5)\n",
    "plt.plot(y_u3, c='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.fill_between([*range(len(yhat3.reshape(-1)))], y_l3, y_u3, label='95%', color='pink', alpha=.4)\n",
    "plt.xlabel('Year',fontsize=20)\n",
    "plt.ylabel('Catch(Kg.)',fontsize=20)\n",
    "plt.title(\"Raidighi\",fontsize=25)\n",
    "plt.xticks(12*np.arange(1,13),np.arange(2013,2025), fontsize=15)\n",
    "\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat2=old2['Future_prediction'].values\n",
    "yhat2_b = 1/len(yhat2)*sum(yhat2)\n",
    "ieta2 = np.sqrt(1/len(yhat2)*sum(np.square(yhat2-yhat2_b)))\n",
    "ieta2\n",
    "\n",
    "CI_L2 = yhat2_b-1.96*ieta2\n",
    "CI_U2 = yhat2_b+1.96*ieta2\n",
    "import matplotlib.pyplot as plt\n",
    "y_l2=yhat2-1.96*ieta2\n",
    "y_u2=yhat2+1.96*ieta2\n",
    "Months2=range(0,len(yhat2))\n",
    "plt.subplots(figsize=(15,6))\n",
    "\n",
    "plt.plot(yhat2.reshape(-1), label='Future prediction')\n",
    "plt.plot(y_l2, label='pred_95', c='red', linestyle='--', alpha=0.5)\n",
    "plt.plot(y_u2, c='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.fill_between([*range(len(yhat2.reshape(-1)))], y_l2, y_u2, label='95%', color='pink', alpha=.4)\n",
    "plt.xlabel('Year',fontsize=20)\n",
    "plt.ylabel('Catch(Kg.)',fontsize=20)\n",
    "plt.title(\"Malancha\",fontsize=25)\n",
    "plt.xticks(12*np.arange(1,13),np.arange(2013,2025), fontsize=15)\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat1=old1['Future_prediction'].values\n",
    "yhat1_b = 1/len(yhat1)*sum(yhat1)\n",
    "ieta1 = np.sqrt(1/len(yhat1)*sum(np.square(yhat1-yhat1_b)))\n",
    "ieta1\n",
    "# alpha=0.05, zalpha/2=1.96\n",
    "ieta1\n",
    "CI_L1 = yhat1_b-1.96*ieta1\n",
    "CI_U1 = yhat1_b+1.96*ieta1\n",
    "import matplotlib.pyplot as plt\n",
    "y_l1=yhat1-1.96*ieta1\n",
    "y_u1=yhat1+1.96*ieta1\n",
    "Months1=range(0,len(yhat1))\n",
    "plt.subplots(figsize=(15,6))\n",
    "\n",
    "plt.plot(yhat1.reshape(-1), label='Future prediction')\n",
    "plt.plot(y_l1, label='pred_95', c='red', linestyle='--', alpha=0.5)\n",
    "plt.plot(y_u1, c='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.fill_between([*range(len(yhat1.reshape(-1)))], y_l1, y_u1, label='95%', color='pink', alpha=.4)\n",
    "plt.xlabel('Year',fontsize=20)\n",
    "plt.ylabel('Catch(Kg.)',fontsize=20)\n",
    "plt.title(\"Diamond harbour\",fontsize=25)\n",
    "plt.xticks(12*np.arange(1,13),np.arange(2013,2025), fontsize=15)\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.2.5 Figure 8 (In manuscript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "\n",
    "\n",
    "plt.plot(yhat1.reshape(-1), label='Future prediction', c='green')\n",
    "plt.plot(y_l1, label='pred_95', c='brown', linestyle='--', alpha=1)\n",
    "plt.plot(y_u1, c='red', linestyle='--', alpha=0.5)\n",
    "plt.fill_between([*range(len(yhat1.reshape(-1)))], y_l1, y_u1, label='95%', color='green', alpha=0.2)\n",
    "plt.xlabel('Year',fontsize=20)\n",
    "plt.ylabel('Catch(Kg.)',fontsize=20)\n",
    "plt.title(\"(a) Diamond harbour\",fontsize=22)\n",
    "plt.xticks(12*np.arange(1,13),np.arange(2013,2025), fontsize=14, rotation=50)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(loc='best', fontsize=13, framealpha=0.2)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(yhat3.reshape(-1), label='Future prediction', c='blue')\n",
    "plt.plot(y_l3, label='pred_95', c='brown', linestyle='--', alpha=1)\n",
    "plt.plot(y_u3, c='red', linestyle='--', alpha=0.5)\n",
    "plt.fill_between([*range(len(yhat3.reshape(-1)))], y_l3, y_u3, label='95%', color='blue', alpha=.2)\n",
    "plt.xlabel('Year',fontsize=20)\n",
    "#plt.ylabel('Catch(Kg.)',fontsize=20)\n",
    "plt.title(\"(b) Raidighi\",fontsize=22)\n",
    "plt.xticks(12*np.arange(1,13),np.arange(2013,2025), fontsize=14, rotation=50)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(loc='best', fontsize=13, framealpha=0.2);\n",
    "\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "\n",
    "\n",
    "plt.plot(yhat2.reshape(-1), label='Future prediction', c='red')\n",
    "plt.plot(y_l2, label='pred_95', c='brown', linestyle='--', alpha=1)\n",
    "plt.plot(y_u2, c='red', linestyle='--', alpha=0.5)\n",
    "plt.fill_between([*range(len(yhat2.reshape(-1)))], y_l2, y_u2, label='95%', color='red', alpha=0.2)\n",
    "plt.xlabel('Year',fontsize=20)\n",
    "#plt.ylabel('Catch(Kg.)',fontsize=20)\n",
    "plt.title(\"(c) Malancha\",fontsize=22)\n",
    "plt.xticks(12*np.arange(1,13),np.arange(2013,2025), fontsize=14, rotation=50)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(loc='best', fontsize=13, framealpha=0.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig('Best_predictions_DHMR.jpeg',dpi=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "* https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/\n",
    "* Meiselwitz, Gabriele. (2020). Social Computing and Social Media. Design, Ethics, User Behavior, and Social Network Analysis 12th International Conference, SCSM 2020, Held as Part of the 22nd HCI International Conference, HCII 2020 Copenhagen, Denmark, July 19â€“24, 2020 Proceedings, Part I. 10.1007/978-3-030-49570-1.\n",
    "* Arai, Kohei. (2021). Intelligent Systems and Applications Proceedings of the 2021 Intelligent Systems Conference (IntelliSys), held on July 15-16, 2021 Proceedings, Springer: Volume 1.\n",
    "* Yi, D. & Ahn, J. & Ji, S.. 2020. An Effective Optimization Method for Machine Learning Based on ADAM. Applied Sciences. 10. 1073. 10.3390/app10031073.\n",
    "* Zhou, S. & Xie, W. & Lu, Y. & Wang, Y. & Zhou, Y. & Hui, N. & Dong, C. (2021). ConvLSTM-Based Wave Forecasts in the South and East China Seas. Frontiers in Marine Science. 8. 680079. 10.3389/fmars.2021.680079."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
